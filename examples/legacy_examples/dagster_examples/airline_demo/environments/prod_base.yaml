resources:
  db_info:
    config:
      db_name:
        env: REDSHIFT_DB
      hostname:
        env: REDSHIFT_ENDPOINT
      port:
        env: REDSHIFT_PORT
      password:
        env: REDSHIFT_PASSWORD
      username:
        env: REDSHIFT_USERNAME
      s3_temp_dir: "dagster-scratch-80542c2"
  file_cache:
    config:
      bucket: "dagster-scratch-80542c2"
      key: "airline-demo"
  pyspark_step_launcher:
    config:
      cluster_id:
        env: EMR_CLUSTER_ID
      local_pipeline_package_path: "."
      deploy_local_pipeline_package: true
      region_name: "us-west-1"
      staging_bucket: "dagster-scratch-80542c2"
      spark_config:
        spark:
          jars:
            packages: com.databricks:spark-avro_2.11:3.0.0,com.databricks:spark-redshift_2.11:2.0.1,com.databricks:spark-csv_2.11:1.5.0,org.postgresql:postgresql:42.2.5,org.apache.hadoop:hadoop-aws:2.6.5,com.amazonaws:aws-java-sdk:1.7.4
  file_manager:
    config:
      s3_bucket: dagster-scratch-80542c2
      s3_prefix: simple-pyspark

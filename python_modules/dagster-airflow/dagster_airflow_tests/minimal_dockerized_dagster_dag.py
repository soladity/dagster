"""Autogenerated by dagster-airflow from pipeline demo_pipeline with env_config:

{
    "context": {"default": {"config": {"log_level": "DEBUG"}}},
    "solids": {
        "multiply_the_word": {"inputs": {"word": {"value": "bar"}}, "config": {"factor": 2}}
    },
}

"""

import datetime

from airflow import DAG
from airflow.operators.dagster_plugin import DagsterOperator

# Set your S3 connection id here, if you do not want to use the default `aws_default` connection
S3_CONN_ID = "aws_default"

dag = DAG(
    dag_id="demo_pipeline",
    description="***Autogenerated by dagster-airflow***",
    default_args={
        "owner": "airflow",
        "depends_on_past": False,
        "start_date": datetime.datetime(2019, 1, 28, 22, 9, 7, 92246),
        "email": ["airflow@example.com"],
        "email_on_failure": False,
        "email_on_retry": False,
        "retries": 1,
        "retry_delay": datetime.timedelta(0, 300),
    },
)

multiply__the__word_word_input__thunk_task = DagsterOperator(
    step="multiply__the__word_word_input__thunk",
    dag=dag,
    image="dagster-airflow-demo",
    task_id="multiply__the__word_word_input__thunk",
    s3_conn_id=S3_CONN_ID,
)
multiply__the__word_transform_task = DagsterOperator(
    step="multiply__the__word_transform",
    dag=dag,
    image="dagster-airflow-demo",
    task_id="multiply__the__word_transform",
    s3_conn_id=S3_CONN_ID,
)
count__letters_transform_task = DagsterOperator(
    step="count__letters_transform",
    dag=dag,
    image="dagster-airflow-demo",
    task_id="count__letters_transform",
    s3_conn_id=S3_CONN_ID,
)

multiply__the__word_word_input__thunk_task.set_downstream(multiply__the__word_transform_task)
multiply__the__word_transform_task.set_downstream(count__letters_transform_task)

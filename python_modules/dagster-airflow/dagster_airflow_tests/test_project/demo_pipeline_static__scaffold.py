'''Static scaffolding autogenerated by dagster-airflow from pipeline demo_pipeline with config:

    context:
      default:
        config: {log_level: DEBUG}
    solids:
      multiply_the_word:
        config: {factor: 2}
        inputs:
          word: {value: bar}
    

By convention, users should attempt to isolate post-codegen changes and customizations to the
"editable" demo_pipeline_editable__scaffold.py file, rather than changing the definitions in this
"static" file. Please let us know if you are encountering use cases where it is necessary to make
changes to the static file.
'''

from airflow import DAG
try:
    from airflow.operators.dagster_plugin import DagsterOperator
except (ModuleNotFoundError, ImportError):
    from dagster_airflow import DagsterOperator


CONFIG = '''
    {
      context: {
        default: {
          config: {
            log_level: "DEBUG"
          }
        }
      },
      solids: {
        multiply_the_word: {
          config: {
            factor: 2
          },
          inputs: {
            word: {
              value: "bar"
            }
          }
        }
      }
    }
'''.strip('\n').strip(' ')

PIPELINE_NAME = 'demo_pipeline'

STEP_EXECUTIONS_MULTIPLY_THE_WORD = [
    {
        'step_key': 'multiply_the_word.word.input_thunk',
        'inputs': [
        ],
        'outputs': [
            {
                'output_name': 'input_thunk_output',
                'key': '{tmp}{sep}{run_id_prefix}multiply__the__word_word_input__thunk___input__thunk__output.pickle'
            },
        ]
    },
    {
        'step_key': 'multiply_the_word.transform',
        'inputs': [
        ],
        'outputs': [
            {
                'output_name': 'result',
                'key': '{tmp}{sep}{run_id_prefix}multiply__the__word_transform___result.pickle'
            },
        ]
    },
]
STEP_EXECUTIONS_COUNT_LETTERS = [
    {
        'step_key': 'count_letters.transform',
        'inputs': [
            {
                'input_name': 'word',
                'key': '{tmp}{sep}{run_id_prefix}multiply__the__word_transform___result.pickle'
            },
        ],
        'outputs': [
            {
                'output_name': 'result',
                'key': '{tmp}{sep}{run_id_prefix}count__letters_transform___result.pickle'
            },
        ]
    },
]

def make_dag(
    dag_id,
    dag_description,
    dag_kwargs,
    s3_conn_id,
    operator_kwargs,
    host_tmp_dir
):
    dag = DAG(
        dag_id=dag_id,
        description=dag_description,
        **dag_kwargs
    )

    tasks = []

    multiply_the_word_task = DagsterOperator(
        step='multiply_the_word',
        config=CONFIG,
        dag=dag,
        tmp_dir='/tmp/results',
        host_tmp_dir=host_tmp_dir,
        image='dagster-airflow-demo',
        task_id='multiply_the_word',
        s3_conn_id=s3_conn_id,
        pipeline_name=PIPELINE_NAME,
        step_executions=STEP_EXECUTIONS_MULTIPLY_THE_WORD,
        **operator_kwargs
    )
    tasks.append(multiply_the_word_task)

    count_letters_task = DagsterOperator(
        step='count_letters',
        config=CONFIG,
        dag=dag,
        tmp_dir='/tmp/results',
        host_tmp_dir=host_tmp_dir,
        image='dagster-airflow-demo',
        task_id='count_letters',
        s3_conn_id=s3_conn_id,
        pipeline_name=PIPELINE_NAME,
        step_executions=STEP_EXECUTIONS_COUNT_LETTERS,
        **operator_kwargs
    )
    tasks.append(count_letters_task)

    multiply_the_word_task.set_downstream(count_letters_task)

    return (dag, tasks)

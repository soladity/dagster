import { DynamicMetaTags } from 'components/MetaTags';
import PyObject from 'components/PyObject';

<DynamicMetaTags
  title="Object Managers | Dagster"
  description="Object Managers determine how to write handle solid outputs and load solid inputs."
/>

# Object Managers

Dagster solids have [inputs and outputs](/overview/solids-pipelines/solids#solid-inputs-and-outputs).  When a solid produces an output, what happens to it?  When a solid needs an input value, how is it loaded?  <PyObject module="dagster" object="ObjectManager" />s, <PyObject module="dagster" object="InputManager" />s, and <PyObject module="dagster" object="OutputManager" />s let the developer decide.

These APIs make it easy separate code that's responsible for logical data transformation from code that's responsible for reading and writing the results.  Solids can focus on business logic, while object managers handle I/O.  This separation makes it easier to test the business logic and run it in different environments.

## Object managers

<PyObject module="dagster" object="ObjectManager" />s are user-provided objects that know how to both load solid inputs and store solid outputs.  For example, an ObjectManager might store and load objects from files on a filesystem.  Each solid output can have its own ObjectManager, or multiple solid outputs can share an ObjectManager. The ObjectManager that's used for handling a particular solid output is automatically used for loading it in subsequent solids.

<p/>

I.e. an ObjectManager handles the teal boxes:

<p align="center">
  <img src="/assets/images/overview/object-managers/object-managers.png" />
</p>

The default ObjectManager, <PyObject module="dagster" object="mem_object_manager" />, stores outputs in memory, but this only works for the single process executor.  Dagster provides out-of-the-box ObjectManagers that pickle objects and save them. These are <PyObject module="dagster" object="fs_object_manager"/>, <PyObject module="dagster_aws.s3" object="s3_object_manager"/>, <PyObject module="dagster_azure.adls2" object="adls2_object_manager"/>, or <PyObject module="dagster_gcp.gcs" object="gcs_object_manager"/>.

ObjectManagers are [resources](/overview/modes-resources-presets/modes-resources), which means users can supply different ObjectManagers for the same solid outputs in different situations.  For example, you might use an in-memory ObjectManager for unit-testing a pipeline and an S3ObjectManager in production.

## Input managers and output managers

ObjectManagers are resources that specify both how to load inputs and handle outputs. You can also define resources that only load inputs or only handle outputs.

<PyObject module="dagster" object="InputManager" />s are for situations where you need to control how inputs are loaded independently of how outputs are stored.  They're useful for loading the inputs at the beginning of a pipeline, as well as for situations where you don't have control over the manager used for an upstream output.

<p/>

<PyObject module="dagster" object="OutputManager" />s are for situations where you need to control how outputs are handled independently of how inputs are loaded.  They're useful for handling the outputs at the end of a pipeline.

<p/>

<PyObject module="dagster" object="ObjectManager" /> is an interface that inherits from both the <PyObject module="dagster" object="InputManager" /> and <PyObject module="dagster" object="OutputManager" /> interfaces:

<p/>

<p align="center">
  <img src="/assets/images/overview/object-managers/manager-venn-diagram.png" width="600px"/>
</p>


## Setting a pipeline-wide object manager

By default, all the inputs and outputs in a pipeline use the same ObjectManager.  This ObjectManager is determined by the <PyObject module="dagster" object="ResourceDefinition" /> provided for the `"object_manager"` resource key.  `"object_manager"` is a resource key that Dagster reserves specifically for this purpose.

Hereâ€™s how to specify that all solid outputs are stored using the <PyObject module="dagster" object="fs_object_manager" />, which pickles outputs and stores them on the local filesystem.  It stores files in a directory with the run ID in the path, so that outputs from prior runs will never be overwritten.

```python literalinclude caption=default_object_manager.py
file:/docs_snippets/docs_snippets/overview/object_managers/default_object_manager.py
```

## Selecting an object manager per output

Not all the outputs in a pipeline should necessarily be stored the same way.  Maybe some of the outputs should live on the filesystem so they can be inspected, and others can be transiently stored in memory.

To select the ObjectManager for a particular output, you can set an `manager_key` on the <PyObject module="dagster" object="OutputDefinition" />, and then refer to that `manager_key` when setting object managers in your <PyObject module="dagster" object="ModeDefinition" />.  In this example, the output of solid1 will go to `fs_object_manager` and the output of solid2 will go to `mem_object_manager`.

```python literalinclude caption=object_manager_per_output.py
file:/docs_snippets/docs_snippets/overview/object_managers/object_manager_per_output.py
startAfter:start_marker
endBefore:end_marker
```

## Providing a custom object manager

If you have specific requirements for where and how your outputs should be stored and retrieved, you can define your own ObjectManager.  For example, if your solids produce Pandas DataFrames that populate tables in a data warehouse, you might write the following:

```python literalinclude caption=custom_object_manager.py
file:/docs_snippets/docs_snippets/overview/object_managers/custom_object_manager.py
startAfter:start_marker
endBefore:end_marker
```

The <PyObject module="dagster" object="object_manager" /> decorator behaves nearly identically to the <PyObject module="dagster" object="resource" /> decorator.  It yields an <PyObject module="dagster" object="ObjectManagerDefinition" />, which is a subclass of <PyObject module="dagster" object="ResourceDefinition" /> that will produce an <PyObject module="dagster" object="ObjectManager" />.

The provided `context` argument for `handle_output` is an <PyObject module="dagster" object="OutputContext" />.  The provided `context` argument for `load_input` is an <PyObject module="dagster" object="InputContext" />.  The linked API documentation lists all the fields that are available on these objects.


## Providing per-output metadata to an object manager

You might want to provide static metadata that controls how particular outputs are stored.  You don't plan to change the metadata at runtime, so it makes more sense to attach it to a definition rather than expose it as a configuration option.

For example, if your pipeline produces DataFrames to populate tables in a data warehouse, you might want to specify that each output always goes to a particular table.  To accomplish this, you can define `metadata` on each <PyObject module="dagster" object="OutputDefinition" />:

```python literalinclude caption=metadata.py
file:/docs_snippets/docs_snippets/overview/object_managers/metadata.py
startAfter:solids_start_marker
endBefore:solids_end_marker
```

The ObjectManager can then access this metadata when storing or retrieving data, via the <PyObject module="dagster" object="OutputContext" />.

In this case, the table names are encoded in the pipeline definition.  If, instead, you want to be able to set them at run time, the next section describes how.

```python literalinclude caption=metadata.py
file:/docs_snippets/docs_snippets/overview/object_managers/metadata.py
startAfter:asset_store_start_marker
endBefore:asset_store_end_marker
```

## Providing per-output config to an object manager

When launching a run, you might want to parameterize how particular outputs are stored.

For example, if your pipeline produces DataFrames to populate tables in a data warehouse, you might want to specify the table that each output goes to at run launch time.

To accomplish this, you can define an `output_config_schema` on the object manager definition. The ObjectManager methods can access this config when storing or loading data, via the <PyObject module="dagster" object="OutputContext" />.

```python literalinclude caption=output_config.py
file:/docs_snippets/docs_snippets/overview/object_managers/output_config.py
startAfter:object_manager_start_marker
endBefore:object_manager_end_marker
```

Then, when executing a pipeline, you can pass in this per-output config.

```python literalinclude caption=output_config.py
file:/docs_snippets/docs_snippets/overview/object_managers/output_config.py
startAfter:execute_start_marker
endBefore:execute_end_marker
```

## Providing an input manager for a root input

When you have a solid at the beginning of a pipeline that operates on data from external source, you might wish to separate that I/O from your solid's business logic, in the same way you would with an object manager if the solid were loading from an upstream output.

To accomplish this, you can define an <PyObject module="dagster" object="InputManager" />.

```python literalinclude caption=root_input_manager.py
file:/docs_snippets/docs_snippets/overview/object_managers/root_input_manager.py
startAfter:start_marker
endBefore:end_marker
```

The <PyObject module="dagster" object="input_manager" /> decorator behaves nearly identically to the <PyObject module="dagster" object="resource" /> decorator.  It yields an <PyObject module="dagster" object="InputManagerDefinition" />, which is a <PyObject module="dagster" object="ResourceDefinition" /> that will produce an <PyObject module="dagster" object="InputManager" />.


## Providing per-input config to an input manager

When launching a run, you might want to parameterize how particular inputs are loaded.

To accomplish this, you can define an `input_config_schema` on the input manager definition.  The load function can access this config when storing or loading data, via the <PyObject module="dagster" object="InputContext" />.

```python literalinclude caption=config_input_manager.py
file:/docs_snippets/docs_snippets/overview/object_managers/config_input_manager.py
startAfter:def_start_marker
endBefore:def_end_marker
```

Then, when executing a pipeline, you can pass in this per-input config.

```python literalinclude caption=config_input_manager.py
file:/docs_snippets/docs_snippets/overview/object_managers/config_input_manager.py
startAfter:execute_start_marker
endBefore:execute_end_marker
```

## Using an input manager with subselection

You might want to execute a subset of solids in your pipeline and control how the inputs of those solids are loaded.

For example, you might have `solid1` that normally produces a table that `solid2` consumes. To debug `solid2`, you might want to run it on a different table than the one normally produced by `solid1`.

To accomplish this, you can define an object manager whose `load_input` method supports both behaviors: loading based on the upstream output or loading based on config.

```python literalinclude caption=subselection.py
file:/docs_snippets/docs_snippets/overview/object_managers/subselection.py
startAfter:start_marker
endBefore:end_marker
```

If `"table_name"` is provided in the input config for `solid2`'s `dataframe` input, the input will be loaded from the supplied config value:
```python literalinclude caption=subselection.py
file:/docs_snippets/docs_snippets/overview/object_managers/subselection.py
startAfter:start_execute_subselection
endBefore:end_execute_subselection
```

Otherwise, it will be loaded from the place that it expects the upstream output has placed it - in this case, a table with the name of the upstream output.

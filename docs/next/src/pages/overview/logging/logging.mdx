import { DynamicMetaTags } from 'components/MetaTags';

<DynamicMetaTags title="Logging | Dagster" />

# Logging

Dagster includes a rich and extensible logging system.

## Logging from a solid

Any solid can emit log messages at any point in its computation:

```python literalinclude caption=builtin_logger.py showLines startLine=4 emphasize-lines=3
file:/docs_snippets/docs_snippets/overview/logging/builtin_logger.py
lines:4-11
```

## Built-in loggers

When you run the pipeline in terminal, you'll find the messages have been logged through a built-in
logger.

<p align="center">
  <img src="/assets/images/overview/logging/cli.png" />
</p>

The `context` object passed to every solid execution includes the built-in log manager, `context.log`.
It exposes the usual `debug`, `info`, `warning`, `error`, and `critical` methods you would expect
anywhere else in Python.

When you run Dagster pipelines in Dagit, you'll notice that log messages are visible as colored
messages in the console:

Logs also stream back to the Dagit frontend in real time:

![Dagit log display](/assets/images/overview/logging/dagit.png)

Dagit exposes a powerful facility for filtering log messages based on execution steps and log levels.

![Dagit log filtering](/assets/images/overview/logging/dagit-filter.png)

## Debugging with logs

What happens if we introduce an error into our solid logic?

```python literalinclude caption=builtin_logger_error.py showLines startLine=4 emphasize-lines=3
file:/docs_snippets/docs_snippets/overview/logging/builtin_logger_error.py
lines:4-11
```

Errors in user code are caught by the Dagster machinery to ensure pipelines gracefully halt or
continue to execute, but messages including the original tracebacks get logged both to the console
and back to Dagit.

Messages at level `ERROR` or above are highlighted both in Dagit and in the console logs, so
we can easily pick them out of logs even without filtering.

![Dagit error logs](/assets/images/overview/logging/dagit-error.png)

In many cases, especially for local development, this log viewer, coupled with solid reexecution,
is sufficient to enable a fast debug cycle for data pipelines.

## Configuring the built-in loggers

Suppose that we've gotten the kinks out of our pipelines developing locally, and now we want to run
in productionâ€”without all of the log spew from `DEBUG` messages that was helpful during development.

Just like solids, loggers can be configured when you run a pipeline. For example, to filter all
messages below `ERROR` out of the colored console logger, add the following snippet to your config
YAML:

```yaml literalinclude caption=config.yaml showLines emphasize-lines=4
file:/docs_snippets/docs_snippets/overview/logging/config.yaml
```

So when you execute the pipeline with that config, you'll only see the ERROR level logs.
![Dagit error logs](/assets/images/overview/logging/cli-error-only.png)

## Environment-specific logging using modes

Logging is environment-specific: you don't want messages generated by data scientists' local
development loops to be aggregated with production messages; on the other hand, you may find that
in production console logging is irrelevant or even counterproductive.

<!-- TODO: update modes link -->

Dagster recognizes this by attaching loggers to [modes](/overview/modes-resources-presets/modes-resources)
so that you can seamlessly switch from, e.g., Cloudwatch logging in production to console logging in
development and test, without changing any of your code.

```python literalinclude caption=logging_modes.py showLines
file:/docs_snippets/docs_snippets/overview/logging/logging_modes.py
```

From Dagit, you can switch your pipeline mode to 'prod' and edit config in order to use the new
Cloudwatch logger, for example:

```yaml literalinclude caption=config_modes.yaml showLines
file:/docs_snippets/docs_snippets/overview/logging/config_modes.yaml
```

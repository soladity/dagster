{"data": {"pipelineOrError": {"__typename": "Pipeline", "dagsterTypeOrError": {"__typename": "RegularDagsterType", "description": "A PySpark data frame.", "inputSchemaType": {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "Permissive.656acde4b33cd2959dace24bc819a382ad2f603f", "description": null, "isRequired": true, "name": "csv"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive.1b26d45852f3d708162bfae4f82d3b5a7c1fdfa4", "description": null, "isRequired": true, "name": "jdbc"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive.c6eedf546204ec7584a9e58140fe62f96a2c935a", "description": null, "isRequired": true, "name": "json"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive.f522f8589af7646fb64a4335acc39326aa76064f", "description": null, "isRequired": true, "name": "orc"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive", "description": null, "isRequired": false, "name": "other"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive.2cf8ba07325130448435f7349b9ca541a6fd54b5", "description": null, "isRequired": true, "name": "parquet"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive.f329d9b6cb2d7dc193e501dee4813f5ee0aace02", "description": null, "isRequired": true, "name": "table"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive.8a0ebf49572482066b3b25638daca4285873281b", "description": null, "isRequired": true, "name": "text"}], "isSelector": true, "key": "Selector.097942361a9736b83235fa389963849c8b661dea", "recursiveConfigTypes": [{"__typename": "RegularConfigType", "description": "", "givenName": "String", "isSelector": false, "key": "String", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            the name of a column of numeric, date, or timestamp type\n                            that will be used for partitioning;\n                            if this parameter is specified, then ``numPartitions``, ``lowerBound``\n                            (inclusive), and ``upperBound`` (exclusive) will form partition strides\n                            for generated WHERE clause expressions used to split the column\n                            ``column`` evenly.\n                        ", "isRequired": false, "name": "column"}, {"__typename": "ConfigTypeField", "configTypeKey": "Int", "description": "the minimum value of ``column`` used to decide partition stride.", "isRequired": false, "name": "lowerBound"}, {"__typename": "ConfigTypeField", "configTypeKey": "Int", "description": "the number of partitions", "isRequired": false, "name": "numPartitions"}, {"__typename": "ConfigTypeField", "configTypeKey": "Array.Any", "description": "\n                            a list of expressions suitable for inclusion in WHERE clauses;\n                            each one defines one partition of the :class:`DataFrame`\n                        ", "isRequired": false, "name": "predicates"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive", "description": "\n                            a dictionary of JDBC database connection arguments. Normally at\n                            least properties \"user\" and \"password\" with their corresponding values.\n                            For example { 'user' : 'SYSTEM', 'password' : 'mypassword' }\n                        ", "isRequired": false, "name": "properties"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "the name of the table.", "isRequired": true, "name": "table"}, {"__typename": "ConfigTypeField", "configTypeKey": "Int", "description": "the maximum value of ``column`` used to decide partition stride.", "isRequired": false, "name": "upperBound"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "a JDBC URL of the form ``jdbc:subprotocol:subname``.", "isRequired": true, "name": "url"}], "isSelector": false, "key": "Permissive.1b26d45852f3d708162bfae4f82d3b5a7c1fdfa4", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [], "isSelector": false, "key": "Permissive", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "Any", "description": "\n                            string, or list of strings, for input path(s).\n                        ", "isRequired": true, "name": "path"}], "isSelector": false, "key": "Permissive.2cf8ba07325130448435f7349b9ca541a6fd54b5", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            defines the line separator that should be used for parsing.\n                            If None is set, it covers all ``\\r``, ``\\r\\n`` and ``\\n``.\n                        ", "isRequired": false, "name": "lineSep"}, {"__typename": "ConfigTypeField", "configTypeKey": "Any", "description": "string, or list of strings, for input path(s).", "isRequired": true, "name": "path"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            an optional glob pattern to only include files with paths matching the pattern.\n                            The syntax follows `org.apache.hadoop.fs.GlobFilter`.\n                            It does not change the behavior of `partition discovery`_.\n                        ", "isRequired": false, "name": "pathGlobFilter"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "\n                            recursively scan a directory for files.\n                            Using this option disables `partition discovery`_..\n                        ", "isRequired": false, "name": "recursiveFileLookup"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "if true, read each file from input path(s) as a single row.", "isRequired": false, "name": "wholetext"}], "isSelector": false, "key": "Permissive.8a0ebf49572482066b3b25638daca4285873281b", "typeParamKeys": []}, {"__typename": "RegularConfigType", "description": null, "givenName": "Any", "isSelector": false, "key": "Any", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            sets a single character used for escaping the escape for the quote character.\n                            If None is set, the default value is escape character\n                            when escape and quote characters are different, ``\u0000`` otherwise.\n                        ", "isRequired": false, "name": "charToEscapeQuoteEscaping"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            allows renaming the new field having malformed string created by ``PERMISSIVE`` mode.\n                            This overrides ``spark.sql.columnNameOfCorruptRecord``.\n                            If None is set, it uses the value specified in ``spark.sql.columnNameOfCorruptRecord``.\n                        ", "isRequired": false, "name": "columnNameOfCorruptRecord"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            sets a single character used for skipping lines beginning with this character.\n                            By default (None), it is disabled.\n                        ", "isRequired": false, "name": "comment"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            sets the string that indicates a date format.\n                            Custom date formats follow the formats at `datetime pattern`_.\n                            This applies to date type.\n                            If None is set, it uses the default value, ``yyyy-MM-dd``.\n                        ", "isRequired": false, "name": "dateFormat"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            sets the string representation of an empty value.\n                            If None is set, it uses the default value, empty string.\n                        ", "isRequired": false, "name": "emptyValue"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            decodes the CSV files by the given encoding type.\n                            If None is set, it uses the default value, ``UTF-8``.\n                        ", "isRequired": false, "name": "encoding"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "\n                            If it is set to ``true``, the specified or inferred schema will be forcibly applied to datasource files,\n                            and headers in CSV files will be ignored.\n                            If the option is set to ``false``, the schema will be validated against all headers in CSV files\n                            or the first header in RDD if the ``header`` option is set to ``true``.\n                            If None is set, ``true`` is used by default.\n                        ", "isRequired": false, "name": "enforceSchema"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            sets a single character used for escaping quotes inside an already quoted value.\n                            If None is set, it uses the default value, ``\\``.\n                        ", "isRequired": false, "name": "escape"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "\n                            uses the first line as names of columns.\n                            If None is set, it uses the default value, ``false``.\n                        ", "isRequired": false, "name": "header"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "\n                            A flag indicating whether or not leading whitespaces from values being read should be skipped.\n                            If None is set, it uses the default value, ``false``.\n                        ", "isRequired": false, "name": "ignoreLeadingWhiteSpace"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "\n                            A flag indicating whether or not trailing whitespaces from values being read should be skipped.\n                            If None is set, it uses the default value, ``false``.\n                        ", "isRequired": false, "name": "ignoreTrailingWhiteSpace"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "\n                            infers the input schema automatically from data.\n                            It requires one extra pass over the data.\n                            If None is set, it uses the default value, ``false``.\n                        ", "isRequired": false, "name": "inferSchema"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            defines the line separator that should be used for parsing.\n                            If None is set, it covers all ``\\r``, ``\\r\\n`` and ``\\n``.\n                            Maximum length is 1 character.\n                        ", "isRequired": false, "name": "lineSep"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            sets a locale as language tag in IETF BCP 47 format.\n                            If None is set, it uses the default value, ``en-US``.\n                            For instance, ``locale`` is used while parsing dates and timestamps.\n                        ", "isRequired": false, "name": "locale"}, {"__typename": "ConfigTypeField", "configTypeKey": "Int", "description": "\n                            defines the maximum number of characters allowed for any given value being read.\n                            If None is set, it uses the default value, ``-1`` meaning unlimited length.\n                        ", "isRequired": false, "name": "maxCharsPerColumn"}, {"__typename": "ConfigTypeField", "configTypeKey": "Int", "description": "\n                            defines a hard limit of how many columns a record can have.\n                            If None is set, it uses the default value, ``20480``.\n                        ", "isRequired": false, "name": "maxColumns"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            allows a mode for dealing with corrupt records during parsing.\n                            If None is set, it uses the default value, ``PERMISSIVE``.\n                        ", "isRequired": false, "name": "mode"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "\n                            parse records, which may span multiple lines.\n                            If None is set, it uses the default value, ``false``.\n                        ", "isRequired": false, "name": "multiLine"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            sets the string representation of a non-number value.\n                            If None is set, it uses the default value, ``NaN``.\n                        ", "isRequired": false, "name": "nanValue"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            sets the string representation of a negative infinity value.\n                            If None is set, it uses the default value, ``Inf``.\n                        ", "isRequired": false, "name": "negativeInf"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            sets the string representation of a null value.\n                            If None is set, it uses the default value, empty string.\n                        ", "isRequired": false, "name": "nullValue"}, {"__typename": "ConfigTypeField", "configTypeKey": "Any", "description": "\n                            string, or list of strings, for input path(s),\n                            or RDD of Strings storing CSV rows.\n                        ", "isRequired": true, "name": "path"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            an optional glob pattern to only include files with paths matching the pattern.\n                            The syntax follows `org.apache.hadoop.fs.GlobFilter`.\n                            It does not change the behavior of `partition discovery`_.\n                        ", "isRequired": false, "name": "pathGlobFilter"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            sets the string representation of a positive infinity value.\n                            If None is set, it uses the default value, ``Inf``.\n                        ", "isRequired": false, "name": "positiveInf"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            sets a single character used for escaping quoted values\n                            where the separator can be part of the value.\n                            If None is set, it uses the default value, ``\"``.\n                            If you would like to turn off quotations, you need to set an empty string.\n                        ", "isRequired": false, "name": "quote"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "\n                            recursively scan a directory for files.\n                            Using this option disables `partition discovery`_..\n                        ", "isRequired": false, "name": "recursiveFileLookup"}, {"__typename": "ConfigTypeField", "configTypeKey": "Float", "description": "\n                            defines fraction of rows used for schema inferring.\n                            If None is set, it uses the default value, ``1.0``.\n                        ", "isRequired": false, "name": "samplingRatio"}, {"__typename": "ConfigTypeField", "configTypeKey": "Any", "description": "\n                            an optional :class:`pyspark.sql.types.StructType` for the input schema\n                            or a DDL-formatted string (For example ``col0 INT, col1 DOUBLE``).\n                        ", "isRequired": false, "name": "schema"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            sets a separator (one or more characters) for each field and value.\n                            If None is set, it uses the default value, ``,``.\n                        ", "isRequired": false, "name": "sep"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            sets the string that indicates a timestamp format.\n                            Custom date formats follow the formats at `datetime pattern`_.\n                            This applies to timestamp type.\n                            If None is set, it uses the default value, ``yyyy-MM-dd'T'HH:mm:ss[.SSS][XXX]``.\n                        ", "isRequired": false, "name": "timestampFormat"}], "isSelector": false, "key": "Permissive.656acde4b33cd2959dace24bc819a382ad2f603f", "typeParamKeys": []}, {"__typename": "RegularConfigType", "description": "", "givenName": "Int", "isSelector": false, "key": "Int", "typeParamKeys": []}, {"__typename": "RegularConfigType", "description": "", "givenName": "Bool", "isSelector": false, "key": "Bool", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "string, name of the table.", "isRequired": true, "name": "tableName"}], "isSelector": false, "key": "Permissive.f329d9b6cb2d7dc193e501dee4813f5ee0aace02", "typeParamKeys": []}, {"__typename": "ArrayConfigType", "description": "List of Array.Any", "isSelector": false, "key": "Array.Any", "typeParamKeys": ["Any"]}, {"__typename": "RegularConfigType", "description": "", "givenName": "Float", "isSelector": false, "key": "Float", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "\n                            allows accepting quoting of all character using backslash quoting mechanism.\n                            If None is set, it uses the default value, ``false``.\n                        ", "isRequired": false, "name": "allowBackslashEscapingAnyCharacter"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "\n                            ignores Java/C++ style comment in JSON records.\n                            If None is set, it uses the default value, ``false``.\n                        ", "isRequired": false, "name": "allowComments"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "\n                            allows leading zeros in numbers (e.g. 00012).\n                            If None is set, it uses the default value, ``false``.\n                        ", "isRequired": false, "name": "allowNumericLeadingZero"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "\n                            allows single quotes in addition to double quotes.\n                            If None is set, it uses the default value, ``true``.\n                        ", "isRequired": false, "name": "allowSingleQuotes"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "\n                            allows JSON Strings to contain unquoted control\n                            characters (ASCII characters with value less than 32,\n                            including tab and line feed characters) or not.\n                        ", "isRequired": false, "name": "allowUnquotedControlChars"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            allows unquoted JSON field names.\n                            If None is set, it uses the default value, ``false``.\n                        ", "isRequired": false, "name": "allowUnquotedFieldNames"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            allows renaming the new field having malformed string created by ``PERMISSIVE`` mode.\n                            This overrides ``spark.sql.columnNameOfCorruptRecord``.\n                            If None is set, it uses the value specified in ``spark.sql.columnNameOfCorruptRecord``.\n                        ", "isRequired": false, "name": "columnNameOfCorruptRecord"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            sets the string that indicates a date format.\n                            Custom date formats follow the formats at `datetime pattern`_.\n                            This applies to date type.\n                            If None is set, it uses the default value, ``yyyy-MM-dd``.\n                        ", "isRequired": false, "name": "dateFormat"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "\n                            whether to ignore column of all null values or empty array/struct during schema inference.\n                            If None is set, it uses the default value, ``false``.\n                        ", "isRequired": false, "name": "dropFieldIfAllNull"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            allows to forcibly set one of standard basic or extended encoding for the JSON files.\n                            For example UTF-16BE, UTF-32LE.\n                            If None is set, the encoding of input JSON will be detected automatically\n                            when the multiLine option is set to ``true``.\n                        ", "isRequired": false, "name": "encoding"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            defines the line separator that should be used for parsing.\n                            If None is set, it covers all ``\\r``, ``\\r\\n`` and ``\\n``.\n                            Maximum length is 1 character.\n                        ", "isRequired": false, "name": "lineSep"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            sets a locale as language tag in IETF BCP 47 format.\n                            If None is set, it uses the default value, ``en-US``.\n                            For instance, ``locale`` is used while parsing dates and timestamps.\n                        ", "isRequired": false, "name": "locale"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            allows a mode for dealing with corrupt records during parsing.\n                            If None is set, it uses the default value, ``PERMISSIVE``.\n                        ", "isRequired": false, "name": "mode"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "\n                            parse one record, which may span multiple lines, per file.\n                            If None is set, it uses the default value, ``false``.\n                        ", "isRequired": false, "name": "multiLine"}, {"__typename": "ConfigTypeField", "configTypeKey": "Any", "description": "\n                            string represents path to the JSON dataset, or a list of paths,\n                            or RDD of Strings storing JSON objects.\n                        ", "isRequired": true, "name": "path"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            an optional glob pattern to only include files with paths matching the pattern.\n                            The syntax follows `org.apache.hadoop.fs.GlobFilter`.\n                            It does not change the behavior of `partition discovery`_.\n                        ", "isRequired": false, "name": "pathGlobFilter"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "\n                            infers all floating-point values as a decimal type.\n                            If the values do not fit in decimal, then it infers them as doubles.\n                            If None is set, it uses the default value, ``false``.\n                        ", "isRequired": false, "name": "prefersDecimal"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "\n                            infers all primitive values as a string type.\n                            If None is set, it uses the default value, ``false``..\n                        ", "isRequired": false, "name": "primitivesAsString"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "\n                            recursively scan a directory for files.\n                            Using this option disables `partition discovery`_..\n                        ", "isRequired": false, "name": "recursiveFileLookup"}, {"__typename": "ConfigTypeField", "configTypeKey": "Float", "description": "\n                            defines fraction of input JSON objects used for schema inferring.\n                            If None is set, it uses the default value, ``1.0``.\n                        ", "isRequired": false, "name": "samplingRatio"}, {"__typename": "ConfigTypeField", "configTypeKey": "Any", "description": "\n                            an optional :class:`pyspark.sql.types.StructType` for the input schema\n                            or a DDL-formatted string (For example ``col0 INT, col1 DOUBLE``).\n                        ", "isRequired": false, "name": "schema"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "\n                            sets the string that indicates a timestamp format.\n                            Custom date formats follow the formats at `datetime pattern`_.\n                            This applies to timestamp type.\n                            If None is set, it uses the default value, ``yyyy-MM-dd'T'HH:mm:ss[.SSS][XXX]``.\n                        ", "isRequired": false, "name": "timestampFormat"}], "isSelector": false, "key": "Permissive.c6eedf546204ec7584a9e58140fe62f96a2c935a", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "Any", "description": "string, or list of strings, for input path(s).", "isRequired": true, "name": "path"}], "isSelector": false, "key": "Permissive.f522f8589af7646fb64a4335acc39326aa76064f", "typeParamKeys": []}], "typeParamKeys": []}, "name": "PySparkDataFrame", "outputSchemaType": {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "Permissive.9e05dd639713be8708881256487ba00fab6c7988", "description": null, "isRequired": true, "name": "csv"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive.4921f38393c4792f3960d08e187d149a90f039a7", "description": null, "isRequired": true, "name": "jdbc"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive.25ccb467c259edcaa6f5739dccf1f4f94f08f52c", "description": null, "isRequired": true, "name": "json"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive.e496856df0b4bed57ad942f66166dfa542bb0563", "description": null, "isRequired": true, "name": "orc"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive", "description": null, "isRequired": false, "name": "other"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive.5536d4e5298d977c5e455c506864ea6d17205f6f", "description": null, "isRequired": true, "name": "parquet"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive.a9bd5d128df3143031bd2ec44f02647d1a0a3d6c", "description": null, "isRequired": true, "name": "saveAsTable"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive.4d4071833d2c9ddb7b8a8d88716290b62f64eab4", "description": null, "isRequired": true, "name": "text"}], "isSelector": true, "key": "Selector.f828a142f84e9b1a176acc4f37226f3ce998938c", "recursiveConfigTypes": [{"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets a single character used for escaping the escape for the quote character. If None is set, the default value is escape character when escape and quote characters are different, ``\u0000`` otherwise..", "isRequired": false, "name": "charToEscapeQuoteEscaping"}, {"__typename": "ConfigTypeField", "configTypeKey": "WriteCompressionText", "description": "compression codec to use when saving to file.", "isRequired": false, "name": "compression"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets the string that indicates a date format. Custom date formats follow the formats at ``java.text.SimpleDateFormat``. This applies to date type. If None is set, it uses the default value, ``yyyy-MM-dd``.", "isRequired": false, "name": "dateFormat"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets the string representation of an empty value. If None is set, it uses the default value, ````.", "isRequired": false, "name": "emptyValue"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets the encoding (charset) of saved csv files. If None is set, the default UTF-8 charset will be used.", "isRequired": false, "name": "encoding"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets a single character used for escaping quotes inside an already quoted value. If None is set, it uses the default value, ``\\``.", "isRequired": false, "name": "escape"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "a flag indicating whether values containing quotes should always be enclosed in quotes. If None is set, it uses the default value ``true``, escaping all values containing a quote character.", "isRequired": false, "name": "escapeQuotes"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "writes the names of columns as the first line. If None is set, it uses the default value, ``false``.", "isRequired": false, "name": "header"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "a flag indicating whether or not leading whitespaces from values being written should be skipped. If None is set, it uses the default value, ``true``.", "isRequired": false, "name": "ignoreLeadingWhiteSpace"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "a flag indicating whether or not trailing whitespaces from values being written should be skipped. If None is set, it uses the default value, ``true``.", "isRequired": false, "name": "ignoreTrailingWhiteSpace"}, {"__typename": "ConfigTypeField", "configTypeKey": "WriteMode", "description": "specifies the behavior of the save operation when data already exists.", "isRequired": false, "name": "mode"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets the string representation of a null value. If None is set, it uses the default value, empty string.", "isRequired": false, "name": "nullValue"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "the path in any Hadoop supported file system.", "isRequired": true, "name": "path"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets a single character used for escaping quoted values where the separator can be part of the value. If None is set, it uses the default value, ``\"``. If an empty string is set, it uses ``u0000`` (null character).", "isRequired": false, "name": "quote"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "a flag indicating whether all values should always be enclosed in quotes. If None is set, it uses the default value ``false``, only escaping values containing a quote character.", "isRequired": false, "name": "quoteAll"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets a single character as a separator for each field and value. If None is set, it uses the default value, ``,``.", "isRequired": false, "name": "sep"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets the string that indicates a timestamp format. Custom date formats follow the formats at ``java.text.SimpleDateFormat``. This applies to timestamp type. If None is set, it uses the default value, ``yyyy-MM-dd'T'HH:mm:ss.SSSXXX``.", "isRequired": false, "name": "timestampFormat"}], "isSelector": false, "key": "Permissive.9e05dd639713be8708881256487ba00fab6c7988", "typeParamKeys": []}, {"__typename": "EnumConfigType", "description": null, "givenName": "WriteCompressionOrc", "isSelector": false, "key": "WriteCompressionOrc", "typeParamKeys": []}, {"__typename": "RegularConfigType", "description": "", "givenName": "String", "isSelector": false, "key": "String", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [], "isSelector": false, "key": "Permissive", "typeParamKeys": []}, {"__typename": "EnumConfigType", "description": null, "givenName": "WriteCompressionText", "isSelector": false, "key": "WriteCompressionText", "typeParamKeys": []}, {"__typename": "EnumConfigType", "description": null, "givenName": "WriteMode", "isSelector": false, "key": "WriteMode", "typeParamKeys": []}, {"__typename": "EnumConfigType", "description": null, "givenName": "WriteCompressionParquet", "isSelector": false, "key": "WriteCompressionParquet", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "WriteCompressionOrc", "description": "compression codec to use when saving to file. This will override ``orc.compress`` and ``spark.sql.orc.compression.codec``. If None is set, it uses the value specified in ``spark.sql.orc.compression.codec``.", "isRequired": false, "name": "compression"}, {"__typename": "ConfigTypeField", "configTypeKey": "WriteMode", "description": "specifies the behavior of the save operation when data already exists.", "isRequired": false, "name": "mode"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "names of partitioning columns.", "isRequired": false, "name": "partitionBy"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "the path in any Hadoop supported file system.", "isRequired": true, "name": "path"}], "isSelector": false, "key": "Permissive.e496856df0b4bed57ad942f66166dfa542bb0563", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "WriteCompressionText", "description": "compression codec to use when saving to file.", "isRequired": false, "name": "compression"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets the string that indicates a date format. Custom date formats follow the formats at ``java.text.SimpleDateFormat``. This applies to date type. If None is set, it uses the default value, ``yyyy-MM-dd``.", "isRequired": false, "name": "dateFormat"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets the encoding (charset) of saved csv files. If None is set, the default UTF-8 charset will be used.", "isRequired": false, "name": "encoding"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "defines the line separator that should be used for writing. If None is set, it uses the default value, ``\\n``.", "isRequired": false, "name": "lineSep"}, {"__typename": "ConfigTypeField", "configTypeKey": "WriteMode", "description": "specifies the behavior of the save operation when data already exists.", "isRequired": false, "name": "mode"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "the path in any Hadoop supported file system.", "isRequired": true, "name": "path"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets the string that indicates a timestamp format. Custom date formats follow the formats at ``java.text.SimpleDateFormat``. This applies to timestamp type. If None is set, it uses the default value, ``yyyy-MM-dd'T'HH:mm:ss.SSSXXX``.", "isRequired": false, "name": "timestampFormat"}], "isSelector": false, "key": "Permissive.25ccb467c259edcaa6f5739dccf1f4f94f08f52c", "typeParamKeys": []}, {"__typename": "RegularConfigType", "description": "", "givenName": "Bool", "isSelector": false, "key": "Bool", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "WriteMode", "description": "specifies the behavior of the save operation when data already exists.", "isRequired": false, "name": "mode"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive", "description": "a dictionary of JDBC database connection arguments. Normally at least properties \"user\" and \"password\" with their corresponding values. For example { 'user' : 'SYSTEM', 'password' : 'mypassword' }.", "isRequired": false, "name": "properties"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "Name of the table in the external database.", "isRequired": true, "name": "table"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "a JDBC URL of the form ``jdbc:subprotocol:subname``.", "isRequired": true, "name": "url"}], "isSelector": false, "key": "Permissive.4921f38393c4792f3960d08e187d149a90f039a7", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "WriteCompressionParquet", "description": "compression codec to use when saving to file. This will override ``spark.sql.parquet.compression.codec``. If None is set, it uses the value specified in ``spark.sql.parquet.compression.codec``.", "isRequired": false, "name": "compression"}, {"__typename": "ConfigTypeField", "configTypeKey": "WriteMode", "description": "specifies the behavior of the save operation when data already exists.", "isRequired": false, "name": "mode"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "names of partitioning columns.", "isRequired": false, "name": "partitionBy"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "the path in any Hadoop supported file system.", "isRequired": true, "name": "path"}], "isSelector": false, "key": "Permissive.5536d4e5298d977c5e455c506864ea6d17205f6f", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "WriteCompressionText", "description": "compression codec to use when saving to file. This will override ``orc.compress`` and ``spark.sql.orc.compression.codec``. If None is set, it uses the value specified in ``spark.sql.orc.compression.codec``.", "isRequired": false, "name": "compression"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "defines the line separator that should be used for writing. If None is set, it uses the default value, ``\\n``.", "isRequired": false, "name": "lineSep"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "he path in any Hadoop supported file system.", "isRequired": true, "name": "path"}], "isSelector": false, "key": "Permissive.4d4071833d2c9ddb7b8a8d88716290b62f64eab4", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "the format used to save.", "isRequired": false, "name": "format"}, {"__typename": "ConfigTypeField", "configTypeKey": "WriteMode", "description": "specifies the behavior of the save operation when data already exists.", "isRequired": false, "name": "mode"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "the table name.", "isRequired": true, "name": "name"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive", "description": "all other string options.", "isRequired": false, "name": "options"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "names of partitioning columns.", "isRequired": false, "name": "partitionBy"}], "isSelector": false, "key": "Permissive.a9bd5d128df3143031bd2ec44f02647d1a0a3d6c", "typeParamKeys": []}], "typeParamKeys": []}}, "id": "26ac40f57de314e909490928714e03d89d2d2f55"}}}

{"data": {"pipelineOrError": {"__typename": "Pipeline", "dagsterTypeOrError": {"__typename": "RegularDagsterType", "description": "A PySpark data frame.", "inputSchemaType": null, "name": "PySparkDataFrame", "outputSchemaType": {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "Permissive.9e05dd639713be8708881256487ba00fab6c7988", "description": null, "isRequired": true, "name": "csv"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive.4921f38393c4792f3960d08e187d149a90f039a7", "description": null, "isRequired": true, "name": "jdbc"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive.25ccb467c259edcaa6f5739dccf1f4f94f08f52c", "description": null, "isRequired": true, "name": "json"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive.e496856df0b4bed57ad942f66166dfa542bb0563", "description": null, "isRequired": true, "name": "orc"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive.5536d4e5298d977c5e455c506864ea6d17205f6f", "description": null, "isRequired": true, "name": "parquet"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive.a9bd5d128df3143031bd2ec44f02647d1a0a3d6c", "description": null, "isRequired": true, "name": "saveAsTable"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive.4d4071833d2c9ddb7b8a8d88716290b62f64eab4", "description": null, "isRequired": true, "name": "text"}], "isSelector": true, "key": "Selector.a0312e1db1f7ea0c9a7469ac84f010793c729c5c", "recursiveConfigTypes": [{"__typename": "EnumConfigType", "description": null, "givenName": "WriteCompressionParquet", "isSelector": false, "key": "WriteCompressionParquet", "typeParamKeys": []}, {"__typename": "EnumConfigType", "description": null, "givenName": "WriteCompressionText", "isSelector": false, "key": "WriteCompressionText", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "WriteCompressionText", "description": "compression codec to use when saving to file. This will override ``orc.compress`` and ``spark.sql.orc.compression.codec``. If None is set, it uses the value specified in ``spark.sql.orc.compression.codec``.", "isRequired": false, "name": "compression"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "defines the line separator that should be used for writing. If None is set, it uses the default value, ``\\n``.", "isRequired": false, "name": "lineSep"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "he path in any Hadoop supported file system.", "isRequired": true, "name": "path"}], "isSelector": false, "key": "Permissive.4d4071833d2c9ddb7b8a8d88716290b62f64eab4", "typeParamKeys": []}, {"__typename": "RegularConfigType", "description": "", "givenName": "Bool", "isSelector": false, "key": "Bool", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "WriteMode", "description": "specifies the behavior of the save operation when data already exists.", "isRequired": false, "name": "mode"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive", "description": "a dictionary of JDBC database connection arguments. Normally at least properties \"user\" and \"password\" with their corresponding values. For example { 'user' : 'SYSTEM', 'password' : 'mypassword' }.", "isRequired": false, "name": "properties"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "Name of the table in the external database.", "isRequired": true, "name": "table"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "a JDBC URL of the form ``jdbc:subprotocol:subname``.", "isRequired": true, "name": "url"}], "isSelector": false, "key": "Permissive.4921f38393c4792f3960d08e187d149a90f039a7", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "WriteCompressionOrc", "description": "compression codec to use when saving to file. This will override ``orc.compress`` and ``spark.sql.orc.compression.codec``. If None is set, it uses the value specified in ``spark.sql.orc.compression.codec``.", "isRequired": false, "name": "compression"}, {"__typename": "ConfigTypeField", "configTypeKey": "WriteMode", "description": "specifies the behavior of the save operation when data already exists.", "isRequired": false, "name": "mode"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "names of partitioning columns.", "isRequired": false, "name": "partitionBy"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "the path in any Hadoop supported file system.", "isRequired": true, "name": "path"}], "isSelector": false, "key": "Permissive.e496856df0b4bed57ad942f66166dfa542bb0563", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "the format used to save.", "isRequired": false, "name": "format"}, {"__typename": "ConfigTypeField", "configTypeKey": "WriteMode", "description": "specifies the behavior of the save operation when data already exists.", "isRequired": false, "name": "mode"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "the table name.", "isRequired": true, "name": "name"}, {"__typename": "ConfigTypeField", "configTypeKey": "Permissive", "description": "all other string options.", "isRequired": false, "name": "options"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "names of partitioning columns.", "isRequired": false, "name": "partitionBy"}], "isSelector": false, "key": "Permissive.a9bd5d128df3143031bd2ec44f02647d1a0a3d6c", "typeParamKeys": []}, {"__typename": "EnumConfigType", "description": null, "givenName": "WriteMode", "isSelector": false, "key": "WriteMode", "typeParamKeys": []}, {"__typename": "EnumConfigType", "description": null, "givenName": "WriteCompressionOrc", "isSelector": false, "key": "WriteCompressionOrc", "typeParamKeys": []}, {"__typename": "RegularConfigType", "description": "", "givenName": "String", "isSelector": false, "key": "String", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "WriteCompressionText", "description": "compression codec to use when saving to file.", "isRequired": false, "name": "compression"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets the string that indicates a date format. Custom date formats follow the formats at ``java.text.SimpleDateFormat``. This applies to date type. If None is set, it uses the default value, ``yyyy-MM-dd``.", "isRequired": false, "name": "dateFormat"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets the encoding (charset) of saved csv files. If None is set, the default UTF-8 charset will be used.", "isRequired": false, "name": "encoding"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "defines the line separator that should be used for writing. If None is set, it uses the default value, ``\\n``.", "isRequired": false, "name": "lineSep"}, {"__typename": "ConfigTypeField", "configTypeKey": "WriteMode", "description": "specifies the behavior of the save operation when data already exists.", "isRequired": false, "name": "mode"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "the path in any Hadoop supported file system.", "isRequired": true, "name": "path"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets the string that indicates a timestamp format. Custom date formats follow the formats at ``java.text.SimpleDateFormat``. This applies to timestamp type. If None is set, it uses the default value, ``yyyy-MM-dd'T'HH:mm:ss.SSSXXX``.", "isRequired": false, "name": "timestampFormat"}], "isSelector": false, "key": "Permissive.25ccb467c259edcaa6f5739dccf1f4f94f08f52c", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "WriteCompressionParquet", "description": "compression codec to use when saving to file. This will override ``spark.sql.parquet.compression.codec``. If None is set, it uses the value specified in ``spark.sql.parquet.compression.codec``.", "isRequired": false, "name": "compression"}, {"__typename": "ConfigTypeField", "configTypeKey": "WriteMode", "description": "specifies the behavior of the save operation when data already exists.", "isRequired": false, "name": "mode"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "names of partitioning columns.", "isRequired": false, "name": "partitionBy"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "the path in any Hadoop supported file system.", "isRequired": true, "name": "path"}], "isSelector": false, "key": "Permissive.5536d4e5298d977c5e455c506864ea6d17205f6f", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [{"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets a single character used for escaping the escape for the quote character. If None is set, the default value is escape character when escape and quote characters are different, ``\u0000`` otherwise..", "isRequired": false, "name": "charToEscapeQuoteEscaping"}, {"__typename": "ConfigTypeField", "configTypeKey": "WriteCompressionText", "description": "compression codec to use when saving to file.", "isRequired": false, "name": "compression"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets the string that indicates a date format. Custom date formats follow the formats at ``java.text.SimpleDateFormat``. This applies to date type. If None is set, it uses the default value, ``yyyy-MM-dd``.", "isRequired": false, "name": "dateFormat"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets the string representation of an empty value. If None is set, it uses the default value, ````.", "isRequired": false, "name": "emptyValue"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets the encoding (charset) of saved csv files. If None is set, the default UTF-8 charset will be used.", "isRequired": false, "name": "encoding"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets a single character used for escaping quotes inside an already quoted value. If None is set, it uses the default value, ``\\``.", "isRequired": false, "name": "escape"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "a flag indicating whether values containing quotes should always be enclosed in quotes. If None is set, it uses the default value ``true``, escaping all values containing a quote character.", "isRequired": false, "name": "escapeQuotes"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "writes the names of columns as the first line. If None is set, it uses the default value, ``false``.", "isRequired": false, "name": "header"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "a flag indicating whether or not leading whitespaces from values being written should be skipped. If None is set, it uses the default value, ``true``.", "isRequired": false, "name": "ignoreLeadingWhiteSpace"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "a flag indicating whether or not trailing whitespaces from values being written should be skipped. If None is set, it uses the default value, ``true``.", "isRequired": false, "name": "ignoreTrailingWhiteSpace"}, {"__typename": "ConfigTypeField", "configTypeKey": "WriteMode", "description": "specifies the behavior of the save operation when data already exists.", "isRequired": false, "name": "mode"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets the string representation of a null value. If None is set, it uses the default value, empty string.", "isRequired": false, "name": "nullValue"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "the path in any Hadoop supported file system.", "isRequired": true, "name": "path"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets a single character used for escaping quoted values where the separator can be part of the value. If None is set, it uses the default value, ``\"``. If an empty string is set, it uses ``u0000`` (null character).", "isRequired": false, "name": "quote"}, {"__typename": "ConfigTypeField", "configTypeKey": "Bool", "description": "a flag indicating whether all values should always be enclosed in quotes. If None is set, it uses the default value ``false``, only escaping values containing a quote character.", "isRequired": false, "name": "quoteAll"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets a single character as a separator for each field and value. If None is set, it uses the default value, ``,``.", "isRequired": false, "name": "sep"}, {"__typename": "ConfigTypeField", "configTypeKey": "String", "description": "sets the string that indicates a timestamp format. Custom date formats follow the formats at ``java.text.SimpleDateFormat``. This applies to timestamp type. If None is set, it uses the default value, ``yyyy-MM-dd'T'HH:mm:ss.SSSXXX``.", "isRequired": false, "name": "timestampFormat"}], "isSelector": false, "key": "Permissive.9e05dd639713be8708881256487ba00fab6c7988", "typeParamKeys": []}, {"__typename": "CompositeConfigType", "description": null, "fields": [], "isSelector": false, "key": "Permissive", "typeParamKeys": []}], "typeParamKeys": []}}, "id": "ea7f4dd5d8c1d66e75350581c5b41aa90b7fe132"}}}
